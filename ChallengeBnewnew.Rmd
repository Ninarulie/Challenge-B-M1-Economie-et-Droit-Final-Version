---
output:
  html_document: default
  pdf_document: default
---
# challenge-b-rprog-m1-eco

---
title: "ChallengeB"
author: "Tiphaine Gouraud & Nina Ruli√©"
output: html_document
---
Github links:
https://github.com/TiphaineGOU
https://github.com/Ninarulie
---

TASK 1B: Prediction House prices in Ames, Iowa
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Load datas and packages

```{r Preparations1, include=TRUE, eval = FALSE, echo=TRUE, warning = FALSE}
install.packages("tidyverse")
install.packages("readr")
install.packages("randomForest")
install.packages("np")

```

```{r Preparations1bis, include=TRUE, echo=TRUE, warning = FALSE}
library(randomForest)
library(tidyverse)
library(readr)
library(dplyr) 
```

```{r load data, include=TRUE, echo=TRUE, warning = FALSE}
train<- read_csv("train.csv")
Test<- read_csv(file = "test.csv")
```
# We choose a ML technique : randomForest

RandomForest is an algorithm which create forest with a number of trees, the more trees in the forest, the more robust is the model. 
RandomForest select randomly a number of features in from the total amount of features. It use these features randomly selected to find the root node. After that it calculate the daughter nodes and repeat this 3 steps until it has formed a tree with a root node and the target as a leaf. And it repeat this 4 steps until it has a n number of trees.
When we train randomForest algorithm to perfom prediction, it takes the test features and use the rules of each randomly created decision tree to predict the out come. The final decision will be the target wich have been reach the most.
RandomForest is used most of the time to make prediction when there is a big amount of variables. In the prediction we are going to do there are 74 variable, which is a lot this is why we think it is relevant to use it.

## Prepare the datas
```{r Praparation 1 : missing values and observations, include=TRUE, warning = FALSE}
colnames(train)

Train2<-train[-1] 
```
We remove id column : no pertinence in the model.

```{r Praparation 2 : missing values, include=TRUE, ECHO=TRUE, warning = FALSE}
remove.vars <- Train2 %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 100) %>% select(feature) %>% unlist
Train2 <- Train2 %>% select(- one_of(remove.vars))
```
We remove variables with a lot of missing observations (as we learned is ChallengeA)

```{r Praparation 3 : missing values and observations,warning = FALSE, include=TRUE, ECHO=TRUE}
Train2 %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 0)
 
Train2 <-Train2 %>% filter(is.na(GarageType) == FALSE, is.na(MasVnrType) == FALSE, is.na(BsmtFinType2) == FALSE, is.na(BsmtExposure) == FALSE, is.na(Electrical) == FALSE)
```
We remove missing observations from the data base.

```{r Praparation 4 : convert character to factors, include=TRUE,warning = FALSE, ECHO=TRUE}
Train3 <-Train2%>%mutate_if(is.character,as.factor)
```
We convert characters to factors.
```{r Praparation 5 : No illegal names, include=TRUE, ECHO=TRUE}
names(Train3)<-make.names(names(Train3))  
```
We do this to make sure, the names of the colomnes are the one we can see.

## Random Forest Model
```{r RandomForest, include=TRUE, ECHO=TRUE, warning = FALSE}
set.seed(1)
Train.fit<-randomForest(Train3$SalePrice~., data=Train3)
```
We train the chosen technique on the training data here, Random Forest.

## Prediction on test data
```{r Prediction 1, include=TRUE,ECHO=TRUE }
Predict.RandomForest<-predict(Train.fit,data=Test) 
```
We now have prediction on the data set with RandomForest.
```{r Prediction 2, include=TRUE}
Train.lm<-lm(data=Train3,SalePrice~.) 
print.lm<-print(Train.lm)
predict.lr<-predict(print.lm, data=Test)
```
Prediction with a a linear regression of our choice here Linear model of SalePrice on all the variables.
```{r Prediction comparison, include=TRUE, ECHO=TRUE}
summary(Predict.RandomForest) 
summary(predict.lr)
```
We use the summary of the prediction to compare the two models.
Here we can see that the RandomForest prediction is more centred to the mean compare to the linear model prediction.

```{r Prediction comparison bis , include=TRUE, ECHO=TRUE} 
x<-c(1:1338)
ggplot()+geom_point(aes(x,Predict.RandomForest))+geom_point(aes(x,predict.lr),col="red")+geom_line(aes(x,186500),col="yellow",size=1.5)
```

Black points are prediction with RandomForest, red point are prediction with Linear regression, the yellow line correspond approximatively to the mean. Here we can see once again that the RandomForest prediction is more centred to the mean compare to the linear model prediction.

```{r last comparison, include=TRUE, ECHO=TRUE }
ggplot()+geom_line(aes(predict.lr,Predict.RandomForest))+geom_line(aes(predict.lr,predict.lr),col="red")

```
Both model nevertheless are approximatively following the same trend, even if there is some extreme cases. The red line is the first bissector (x=x), we see that on average, the two model predict approximatively the same values.


# Task 2B: Overfitting in Machine Learning

## Challenge A dataset and packages we need 
```{r Require Challenge A Task2, include =TRUE, ECHO=TRUE}
# Packages
library(tidyverse)
library(caret)
library(np)

### Model : y = x^3+z , x and z normally distributed : mean = 0 and standard deviation = 1

set.seed(1)
Nsim <- 150
b <- c(0,1)
x0 <- rep(1, Nsim)
x1 <- rnorm(n = Nsim)

X <- cbind(x0, x1^3)
y.true <- X %*% b

eps <- rnorm(n = Nsim)
y <- X %*% b + eps

df <- tbl_df(y[,1]) %>% rename(y = value) %>% bind_cols(tbl_df(x1)) %>% rename(x = value) %>% bind_cols(tbl_df(y.true[,1])) %>% rename(y.true = value)

training.index <- createDataPartition(y = y, times = 1, p = 0.8)
df <- df %>% mutate(which.data = ifelse(1:n() %in% training.index$Resample1, "training", "test"))

training <- df %>% filter(which.data == "training")
test <- df %>% filter(which.data == "test")
lm.fit <- lm(y ~ x, data = training)
summary(lm.fit)

df <- df %>% mutate(y.lm = predict(object = lm.fit, newdata = df))
training <- training %>% mutate(y.lm = predict(object = lm.fit))
```
We just copied and pasted what we did in the challenge A.

# Step 1
## Low-flexibility local linear model

```{r Low-flexibility local linear model, include=TRUE, ECHO=TRUE}
ll.fit.lowflex <- npreg(y ~ x, data = training, method = "ll", bws = 0.5)
summary(ll.fit.lowflex)
```
We create a low flexibility local linear model such that it fit perfectly with all the data of the set training1.

# Step 2
## High-flexibility Local model
```{r High-flexibility local linear model, include=TRUE, ECHO=TRUE}
ll.fit.highflex<-npreg(y ~ x, data = training, method = "ll", bws = 0.01)
summary(ll.fit.highflex)

```
We create a higher flexibility local linear model such that it can be true with other datas than the dataset.

# Step 3
## It's very long to run because we import the 2 entire files.
```{r Plot with training datas, include=TRUE, ECHO=TRUE}
y.high = predict(object = ll.fit.highflex, newdata = training)
y.low = predict(object = ll.fit.lowflex, newdata = training)

ggplot(training) + geom_point (data = training,aes(x,y)) + geom_line(aes(x,y.true), colour = "black", size = 0.8) + geom_line (mapping = aes(x = x, y = y.high), colour = "blue") + geom_line (mapping = aes(x = x, y = y.low), colour = "red")
```

Figure 1 task B : PRedictions of ll.fit.lowflex ans LL.fit.highflex on training data.
We plot the tow models to compare them.

#Step 4
The high flexibility function has less bias, indeed it's closer to the points : the obeservation. It's also the prediction more variable, indeed it's less mothy than the red ligne (low flexibility model) that is closer than the black ligne witch is the "true" model.

#Step 5
```{r Plot with testing datas, include=TRUE, ECHO=TRUE}

##repete the same 3 first steps on testing

y.high.2 = predict(object = ll.fit.highflex, newdata = test)
y.low.2 = predict(object = ll.fit.lowflex, newdata = test)

ggplot(test) + geom_point (data = test,aes(x,y)) + geom_line(aes(x,y.true), colour = "black", size = 0.8) + geom_line (mapping = aes(x = x, y = y.high.2), colour = "blue") + geom_line (mapping = aes(x = x, y = y.low.2), colour = "red")

```

Figure 2 task B : PRedictions of ll.fit.lowflex ans LL.fit.highflex on test data.

We apply the model created on the testing data set.

# Step 6
```{r Create a vector of bandwidth, include=TRUE, ECHO=TRUE}
bw <- seq(0.01, 0.5, by = 0.001)
```
We create the vector of bandwidth.

#Step 7
## Local linear model on training data for different bandwidth.
```{r , local linear model on training data set, include=TRUE, ECHO=TRUE}
llestime<-lapply(X = bw, FUN = function(bw) {npreg(y ~ x, data = training, method = "ll", bws = bw)})
```
We estimate a local linear model y ~ x on the training data with each bandwidth.
#Step 8
```{r compute MSE on training data, include=TRUE, ECHO=TRUE}
mse.training <- function(fit.model){
  predictions <- predict(object = fit.model, newdata = training)
  training %>% mutate(squared.error = (y - predictions)^2) %>% summarize(mse = mean(squared.error))}
mse.train.results <- unlist(lapply(X = llestime, FUN = mse.training))
```
We compute for each bandwidth the MSE on the training data

#Step 9
```{r compute MSE on testing data, include=TRUE,ECHO=TRUE}
mse.testing <- function(fit.model){
  predictions <- predict(object = fit.model, newdata = test)
  test %>% mutate(squared.error = (y - predictions)^2) %>% summarize(mse = mean(squared.error))}
mse.test.results <- unlist(lapply(X = llestime, FUN = mse.testing))
```
We compute for each bandwidth the MSE on the test data.

#Step10
```{r Plot both, include=TRUE, ECHO=TRUE}
mse.df <- tbl_df(data.frame(bandwidth = bw, mse.training = mse.train.results, mse.testing = mse.test.results))
ggplot(mse.df)+geom_line(mapping=aes(bw,mse.training),colour="blue")+geom_line(mapping=aes(bw,mse.testing),colour="orange")
```


Figure 3 task B : MSE on training and test data for differen bandwidth local linear regression.

TASK 3 : Privacy Regulation compliance in France
## /!\ It's very long to run because we import and read the 2 entire files.
```{r import datas, ECHO=TRUE, warning=FALSE, include=TRUE}
library(readr)
library(readxl)
CNIL<- read_delim("OpenCNIL_Organismes_avec_CIL_VD_20171204.csv",  ";", escape_double = FALSE, trim_ws = TRUE)
SIRENE<- read_delim("rprog/sirc-17804_9075_14211_2017340_E_Q_20171207_022339046.csv", ";", escape_double = FALSE, trim_ws = TRUE)
### have to be change by 
## SIREN<-('sirc-17804_9075_14209_201710_L_M_20171101_030132835.csv')
## just too long to run 

```

```{r Names colomnes, include=TRUE, ECHO=TRUE, warning=FALSE}
colnames(CNIL)
colnames(CNIL)[colnames(CNIL)=="Siren"] <- "SIREN"
View(CNIL)
```

```{r Table Departement, include=TRUE, ECHO=TRUE, warning=FALSE}
cnil2 <- subset(CNIL, nchar(CNIL$Code_Postal) > 4,)
# Selecting the postal codes longer than 4 and placing them into cnil2
cnil3 <- subset(cnil2, nchar(cnil2$Code_Postal) < 6,)
# Among cnil2, selecting the postal codes smaller than 6: now, cnil3 contains only the correct postal codes with 5 numbers

cp <- sub ("^(\\d{2}).*$", "\\1", cnil3$Code_Postal);cp2 <- subset(cp, nchar(cp) < 3,)
# Creating a dataframe which contains only the 2 first numbers of the postal codes

nicetable<-data.frame(table(unlist(cp2)))
# Creating the nice table containing the number of organizations per department
colnames(nicetable)[colnames(nicetable)=="Var1"] <- "Departement";colnames(nicetable)[colnames(nicetable)=="Freq"] <- "Number of organizations"
print(nicetable)
View(nicetable)
```

Table that shows the number a organizations that has nominated a CNIL (col: Freq) by departements (col : Var1).

```{r Merge, include=TRUE, ECHO=TRUE, warning=FALSE}

Merge<-merge(CNIL,SIRENE, by="SIREN")

colnames(Merge)
```
We merged the two table into one : adding info about companies identified by 
"SIREN" from one data set into the other.

```{r Histo of the size of the companies that nominated a CIL, include = TRUE, warning=FALSE }
summary(Merge$TEFEN)
MergeFactor <- as.factor(Merge$TEFEN)

ggplot(Merge) + geom_histogram(aes(TEFEN), stat="count",fill="pink") + ylab("Number of companies") + xlab("Number of employees / 10")

```
You an see a cute pink histogram of the size of the companies that nominated a CIL (/10).
We notice that middle size companies that are the most nominating CIL.